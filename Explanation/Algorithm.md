# الگوریتم‌های رگرسیون Ridge و Lasso

## تعریف کلی Regularization

فهوم علمی: Regularization تکنیکی برای کاهش overfitting با افزودن یک جریمه (penalty term) به تابع هزینه است. این جریمه از بزرگ شدن بیش از حد پارامترهای مدل جلوگیری کرده و تعادل بهینه بین بایاس و واریانس ایجاد می‌کند. در یادگیری ماشین، این روش به مدل کمک می‌کند تا بهتر تعمیم یابد.

مثال: مثل ورزشکاری که هم قدرت دارد (خطای آموزشی کم) و هم انعطاف (توانایی پذیرش داده جدید) - Regularization مدل را "ورزشکار" می‌کند!

##  رگرسیون Ridge (L2 Regularization)

تعریف علمی: در رگرسیون Ridge، تابع هزینه شامل مجموع مربعات خطا به علاوه ضریب λ ضربدر مجموع مربعات ضرایب است:
J(β) = Σ(yᵢ - ŷᵢ)² + λΣβⱼ²

این روش ضرایب را به سمت صفر می‌کشد اما معمولاً دقیقاً صفر نمی‌کند، که برای موقعیت‌هایی که همه متغیرها مرتبط هستند مفید است.

مثال: مدیر پروژه‌ای که به همه اعضای تیم کمی کار می‌دهد (هیچ‌کس اخراج نمی‌شود، اما همه بار کاری کمتری دارند).

## رگرسیون Lasso (L1 Regularization)

تعریف علمی: رگرسیون Lasso جریمه قدر مطلق ضرایب را اعمال می‌کند:
J(β) = Σ(yᵢ - ŷᵢ)² + λΣ|βⱼ|

به دلیل خاصیت هندسی هنجار L1، برخی ضرایب دقیقاً صفر می‌شوند، که منجر به انتخاب خودکار ویژگی‌ها و ایجاد مدل‌های تنک (sparse) می‌گردد.

مثال: مدیر پروژه‌ای که فقط اعضای کلیدی تیم را نگه می‌دارد و بقیه را حذف می‌کند (انتخاب ویژگی).

##  مقایسه Ridge و Lasso

تحلیل علمی: از نظر هندسی، Ridge محدوده مجاز را به صورت دایره (L2) و Lasso را به صورت لوزی (L1) تعریف می‌کند. محل برخورد منحنی خطا با این محدوده، جواب بهینه را مشخص می‌کند. لوزی Lasso تمایل دارد در گوشه‌ها تقاطع پیدا کند که مربوط به صفر شدن برخی ضرایب است.

مثال: Ridge مثل کارمندی که همه پروژه‌ها را کمی انجام می‌دهد، Lasso مثل کارمندی که روی چند پروژه اصلی تمرکز می‌کند.

## پارامتر λ (لامبدا)

تعریف علمی: λ پارامتر تنظیم است که قدرت جریمه‌سازی را کنترل می‌کند. مقدار بهینه λ معمولاً از طریق اعتبارسنجی متقابل (Cross-Validation) تعیین می‌شود. افزایش λ باعث کاهش واریانس اما افزایش بایاس می‌گردد (مبادله بایاس-واریانس).

مثال: λ مثل ترموستات - زیادش مدل را سرد (ساده) می‌کند، کمش مدل را گرم (پیچیده) می‌کند.

##  الگوریتم اجرا و آموزش

مراحل : 1) استانداردسازی ویژگی‌ها، 2) انتخاب محدوده λ، 3) آموزش مدل برای هر λ، 4) ارزیابی با اعتبارسنجی متقابل، 5) انتخاب λ بهینه، 6) آموزش مدل نهایی با همه داده‌ها. در Lasso معمولاً از الگوریتم coordinate descent استفاده می‌شود.

مثال: مثل آشپزی که: مواد را آماده می‌کند (استانداردسازی)، نمک را تنظیم می‌کند (λ)، می‌چشد (ارزیابی)، و نسخه نهایی را می‌پزد.

## مثال کاربردی: پیش‌بینی قیمت مسکن

کاربرد علمی: در مسائل regression با ابعاد بالا، Ridge زمانی مناسب است که همه 20 ویژگی ساختمانی مؤثر باشند. Lasso وقتی مناسب است که فقط 5 ویژگی اصلی (متراژ، محل، سن بنا، تعداد اتاق، امکانات) تعیین‌کننده باشند. Elastic Net وقتی که برخی ویژگی‌ها همبستگی دارند.

مثال: Ridge همه معیارها (حتی رنگ در) را کم‌اثر در نظر می‌گیرد، Lasso فقط معیارهای اصلی (متراژ، محل) را نگه می‌دارد.

## مزایا و معایب 

تحلیل: مزیت اصلی Ridge پایداری عددی و عملکرد بهتر با متغیرهای همبسته است. مزیت اصلی Lasso تفسیرپذیری و ایجاد مدل‌های تنک است. نقطه ضعف Ridge حفظ همه متغیرها و ضعف Lasso انتخاب ناپایدار در حضور همبستگی بالا است.

مثال: Ridge مثل دانشجویی که همه کتاب‌ها را کمی می‌خواند (پایدار)، Lasso مثل دانشجویی که فقط چند کتاب اصلی را عمیق می‌خواند (متمرکز).

 ## کاربرد ها:
 
الگوریتم Ridge در پردازش سیگنال، ژنومیکس با همبستگی بالا. 
الگوریتم Lasso در متن‌کاوی (انتخاب کلمات کلیدی)، ژنتیک (انتخاب ژن‌های مؤثر).

مثال: در پزشکی: Lasso ژن‌های بیماری‌زا را شناسایی می‌کند، Ridge همه شاخص‌های سلامتی را در نظر می‌گیرد.

## جمع‌بندی نهایی

دیدگاه علمی: Regularization راه‌حلی برای مسئله بایاس-واریانس در یادگیری ماشین است. Ridge با هنجار L2 از overfitting جلوگیری می‌کند، Lasso با هنجار L1 هم regularization و هم انتخاب ویژگی انجام می‌دهد. انتخاب بین آنها بستگی به ساختار داده و هدف تحلیل دارد.

مثال نهایی: مثل دو استراتژی سرمایه‌گذاری: Ridge (سرمایه‌گذاری در همه سهام با وزن کم)، Lasso (سرمایه‌گذاری متمرکز در چند سهام برتر). انتخاب بستگی به تحمل ریسک (overfitting) و هدف سرمایه‌گذار دارد.
